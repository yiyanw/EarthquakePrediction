{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Environment ###\n",
    "\n",
    "#from platform import python_version\n",
    "#print(python_version())\n",
    "\n",
    "#pip install tensorflow\n",
    "\n",
    "#pip install keras\n",
    "\n",
    "#pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import metrics\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size:  1064\n",
      "train_size: 744\n"
     ]
    }
   ],
   "source": [
    "def split_data(index, train_percent):\n",
    "    \n",
    "    filename = \"./tagged/\" + str(index) + \"_tagged.csv\"\n",
    "    data = pd.read_csv(filename)\n",
    "    data_len = data.shape[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data = data.drop(columns=['date'])\n",
    "\n",
    "    print(\"Total size: \", data.shape[0])\n",
    "    train_size = int(data_len * train_percent)\n",
    "    print(\"train_size:\",int(train_size))\n",
    "    \n",
    "    train_dataframe = data.loc[:train_size - 1,:]\n",
    "    \n",
    "    \n",
    "    valid_dataframe = data.loc[train_size:,:]\n",
    "    \n",
    "    \n",
    "    train_array = train_dataframe.to_numpy()\n",
    "    valid_array = valid_dataframe.to_numpy()\n",
    "    \n",
    "    trainX = []\n",
    "    trainY = []\n",
    "    validX = []\n",
    "    validY = []\n",
    "    \n",
    "    for value in train_array:\n",
    "        trainX.append(value[:-1])\n",
    "        trainY.append(value[-1])\n",
    "        \n",
    "    for value in valid_array:\n",
    "        validX.append(value[:-1])\n",
    "        validY.append(value[-1])\n",
    "    \n",
    "    features = array(data.columns)[:-1]\n",
    "    #print(array(data.columns)[-1])\n",
    "    #print(features)\n",
    "    return trainX, trainY, validX, validY, features\n",
    "    \n",
    "#     trainY = np.array(trainY).reshape((-1, len(trainY), 1))\n",
    "#     trainX = np.array(trainX).reshape((-1, len(trainX), len(trainX[0])))\n",
    "    \n",
    "#     validY = np.array(validY).reshape((-1, len(validY), 1))\n",
    "#     validX = np.array(validX).reshape((-1, len(validX), len(validX[0])))\n",
    "\n",
    "    \n",
    "#     return trainX, trainY, validX, validY, features\n",
    "\n",
    "trainX, trainY, validX, validY, features = split_data(0, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainX, trainY):\n",
    "    \n",
    "    from keras.layers import Dropout\n",
    "\n",
    "    trainX = np.array(trainX)\n",
    "    y_train = np.array(trainY)\n",
    "\n",
    "    #Reshape the data into 3-D array\n",
    "    x_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "\n",
    "    # Initialising the RNN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (trainX.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a second LSTM layer and Dropout layer\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a third LSTM layer and Dropout layer\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a fourth LSTM layer and and Dropout layer\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    # For Full connection layer we use dense\n",
    "    # As the output is 1D so we use unit=1\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "    #compile and fit the model on 30 epochs\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    model.fit(x_train, y_train, epochs = 30, batch_size = 50)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_valid(model, validX, validY):\n",
    "\n",
    "    #Convert x_test to a numpy array \n",
    "    x_test = np.array(validX)\n",
    "    y_test = np.array(validY)\n",
    "\n",
    "    #Reshape the data into 3-D array\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "\n",
    "    #check predicted values\n",
    "    predictions = model.predict(x_test) \n",
    "    \n",
    "    # #Undo scaling\n",
    "    # predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "     #Calculate RMSE score\n",
    "    rmse=np.sqrt(np.mean(((predictions- y_test)**2)))\n",
    "    print(\"Accuracy is \",rmse)\n",
    "    return predictions\n",
    "    \n",
    "def predict(model, testX):\n",
    "    x_test = np.array(validX)\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n",
    "    predictions = model.predict(x_test) \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 11s 400ms/step - loss: 0.9913\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 6s 394ms/step - loss: 1.0213\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 8s 529ms/step - loss: 1.1972\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 7s 486ms/step - loss: 0.9309\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 7s 468ms/step - loss: 0.9622\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 1.1010\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 1.0263\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 6s 430ms/step - loss: 1.1261\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 1.2424\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 6s 429ms/step - loss: 0.8827\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 7s 441ms/step - loss: 1.0686\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 7s 438ms/step - loss: 1.0453\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 7s 475ms/step - loss: 1.2279\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 1.1979\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 1.0598\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 6s 415ms/step - loss: 1.0214\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 6s 414ms/step - loss: 1.0843\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 6s 417ms/step - loss: 1.2334\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 6s 423ms/step - loss: 1.0365\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 7s 465ms/step - loss: 1.3454\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 1.1616\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 6s 421ms/step - loss: 1.2084\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 7s 435ms/step - loss: 1.1286\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 6s 403ms/step - loss: 1.0489\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 6s 407ms/step - loss: 1.2022\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 6s 413ms/step - loss: 0.9439\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 7s 444ms/step - loss: 0.9479\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 1.2444\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 6s 422ms/step - loss: 1.2120\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 7s 435ms/step - loss: 0.9795\n",
      "Accuracy is  0.9608836529728173\n"
     ]
    }
   ],
   "source": [
    "my_model = train_model(trainX, trainY)\n",
    "predictions = predict_valid(my_model, validX, validY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
